{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04306868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from rouge import Rouge\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import log_loss, roc_auc_score, average_precision_score\n",
    "# PrecisionRecallDisplay, RocCurveDisplay\n",
    "from malnis import show\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b58f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/jarobyte/scratch/malnis_dataset/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4e655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7172, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>rl</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relevance</th>\n",
       "      <th>original_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>Due to the lack of structured knowledge applie...</td>\n",
       "      <td>Index Terms—Machine learning, knowledge discov...</td>\n",
       "      <td>[Text classification [226], text clustering [2...</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.095941</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>[Index Terms—Machine learning, knowledge disco...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7554</th>\n",
       "      <td>Obtaining enough labeled data to robustly trai...</td>\n",
       "      <td>One of the greatest roadblocks to using modern...</td>\n",
       "      <td>[“Lawyer”); moreover, these sources might be c...</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.104247</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>[One of the greatest roadblocks to using moder...</td>\n",
       "      <td>[True, False, True, False, False, False, False...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>Word embeddings, i.e., low-dimensional vector ...</td>\n",
       "      <td>Recently some studies have shown that text cla...</td>\n",
       "      <td>[A recent work (Schuster et al., 2020) showed ...</td>\n",
       "      <td>0.407018</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>[Recently some studies have shown that text cl...</td>\n",
       "      <td>[False, False, True, False, False, False, Fals...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>In this paper our objectives are, first, netwo...</td>\n",
       "      <td>It is commonsense that how you look at an obje...</td>\n",
       "      <td>[Views are commonly different sensory signals,...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[It is commonsense that how you look at an obj...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>This paper describes TextTiling, an algorithm ...</td>\n",
       "      <td>Accurately representing the distance between t...</td>\n",
       "      <td>[Most similar to our method is that of Wan (20...</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>[Accurately representing the distance between ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "7593  Due to the lack of structured knowledge applie...   \n",
       "7554  Obtaining enough labeled data to robustly trai...   \n",
       "4892  Word embeddings, i.e., low-dimensional vector ...   \n",
       "4169  In this paper our objectives are, first, netwo...   \n",
       "6690  This paper describes TextTiling, an algorithm ...   \n",
       "\n",
       "                                               document  \\\n",
       "7593  Index Terms—Machine learning, knowledge discov...   \n",
       "7554  One of the greatest roadblocks to using modern...   \n",
       "4892  Recently some studies have shown that text cla...   \n",
       "4169  It is commonsense that how you look at an obje...   \n",
       "6690  Accurately representing the distance between t...   \n",
       "\n",
       "                                                summary        r1        r2  \\\n",
       "7593  [Text classification [226], text clustering [2...  0.278846  0.095941   \n",
       "7554  [“Lawyer”); moreover, these sources might be c...  0.295455  0.104247   \n",
       "4892  [A recent work (Schuster et al., 2020) showed ...  0.407018  0.186364   \n",
       "4169  [Views are commonly different sensory signals,...  0.257143  0.090909   \n",
       "6690  [Most similar to our method is that of Wan (20...  0.206349  0.037975   \n",
       "\n",
       "            rl                                          sentences  \\\n",
       "7593  0.259615  [Index Terms—Machine learning, knowledge disco...   \n",
       "7554  0.272727  [One of the greatest roadblocks to using moder...   \n",
       "4892  0.385965  [Recently some studies have shown that text cl...   \n",
       "4169  0.250000  [It is commonsense that how you look at an obj...   \n",
       "6690  0.158730  [Accurately representing the distance between ...   \n",
       "\n",
       "                                              relevance  original_sentences  \n",
       "7593  [False, False, False, False, False, False, Fal...                 685  \n",
       "7554  [True, False, True, False, False, False, False...                 246  \n",
       "4892  [False, False, True, False, False, False, Fals...                 202  \n",
       "4169  [False, False, False, False, False, False, Fal...                 240  \n",
       "6690  [False, False, False, False, False, False, Fal...                 246  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle(data_folder + \"data_train.pkl\")\n",
    "show(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66090898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>rl</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relevance</th>\n",
       "      <th>original_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>We propose the task of free-form and open-ende...</td>\n",
       "      <td>Index Terms—Deep learning, visual analytics, i...</td>\n",
       "      <td>[Research combining both image and text data h...</td>\n",
       "      <td>0.249240</td>\n",
       "      <td>0.117400</td>\n",
       "      <td>0.218845</td>\n",
       "      <td>[Index Terms—Deep learning, visual analytics, ...</td>\n",
       "      <td>[False, False, False, False, True, False, Fals...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>In this paper, we propose a novel neural netwo...</td>\n",
       "      <td>Document summarization aims to produce fluent ...</td>\n",
       "      <td>[For each sentence, we apply an RNN with Gated...</td>\n",
       "      <td>0.281407</td>\n",
       "      <td>0.112281</td>\n",
       "      <td>0.281407</td>\n",
       "      <td>[Document summarization aims to produce fluent...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Learning to rank with biased click data is a w...</td>\n",
       "      <td>CCS CONCEPTS • Information systems→ Learning t...</td>\n",
       "      <td>[Most recently, a new approach for de-biasing ...</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.289544</td>\n",
       "      <td>[CCS CONCEPTS • Information systems→ Learning ...</td>\n",
       "      <td>[True, False, False, False, False, False, Fals...</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>We present the Compressive Transformer, an att...</td>\n",
       "      <td>Transformers (Vaswani et al., 2017) have achie...</td>\n",
       "      <td>[on this task as their primary evaluation (Dai...</td>\n",
       "      <td>0.254144</td>\n",
       "      <td>0.075314</td>\n",
       "      <td>0.232044</td>\n",
       "      <td>[Transformers (Vaswani et al., 2017) have achi...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>We propose a method for online news stream clu...</td>\n",
       "      <td>ACM Reference Format: Doug Beeferman and Hang ...</td>\n",
       "      <td>[[17] is the first to include BERT contextual ...</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.094203</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>[ACM Reference Format: Doug Beeferman and Hang...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "5367  We propose the task of free-form and open-ende...   \n",
       "4278  In this paper, we propose a novel neural netwo...   \n",
       "307   Learning to rank with biased click data is a w...   \n",
       "4413  We present the Compressive Transformer, an att...   \n",
       "2963  We propose a method for online news stream clu...   \n",
       "\n",
       "                                               document  \\\n",
       "5367  Index Terms—Deep learning, visual analytics, i...   \n",
       "4278  Document summarization aims to produce fluent ...   \n",
       "307   CCS CONCEPTS • Information systems→ Learning t...   \n",
       "4413  Transformers (Vaswani et al., 2017) have achie...   \n",
       "2963  ACM Reference Format: Doug Beeferman and Hang ...   \n",
       "\n",
       "                                                summary        r1        r2  \\\n",
       "5367  [Research combining both image and text data h...  0.249240  0.117400   \n",
       "4278  [For each sentence, we apply an RNN with Gated...  0.281407  0.112281   \n",
       "307   [Most recently, a new approach for de-biasing ...  0.321716  0.160558   \n",
       "4413  [on this task as their primary evaluation (Dai...  0.254144  0.075314   \n",
       "2963  [[17] is the first to include BERT contextual ...  0.255102  0.094203   \n",
       "\n",
       "            rl                                          sentences  \\\n",
       "5367  0.218845  [Index Terms—Deep learning, visual analytics, ...   \n",
       "4278  0.281407  [Document summarization aims to produce fluent...   \n",
       "307   0.289544  [CCS CONCEPTS • Information systems→ Learning ...   \n",
       "4413  0.232044  [Transformers (Vaswani et al., 2017) have achi...   \n",
       "2963  0.255102  [ACM Reference Format: Doug Beeferman and Hang...   \n",
       "\n",
       "                                              relevance  original_sentences  \n",
       "5367  [False, False, False, False, True, False, Fals...                 497  \n",
       "4278  [False, False, False, False, False, False, Fal...                 238  \n",
       "307   [True, False, False, False, False, False, Fals...                 401  \n",
       "4413  [False, False, False, False, False, False, Fal...                 357  \n",
       "2963  [False, False, False, False, False, False, Fal...                 185  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_pickle(data_folder + \"data_dev.pkl\")\n",
    "show(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db591d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2089747,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets = np.concatenate(train.relevance.to_list())\n",
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cf377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"/home/jarobyte/scratch/malnis_dataset/data/classical_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64f084",
   "metadata": {},
   "source": [
    "# Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe652c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 5.97 s, total: 2min 27s\n",
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2089747"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# corpus = sum([d[\"sentences\"] for d in tqdm(train_records)], start = [])\n",
    "corpus = train.sentences.sum()\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25147eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.3 s, sys: 489 ms, total: 36.8 s\n",
      "Wall time: 36.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2089747, 60166)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_features = vectorizer.fit_transform(corpus)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bcfcc03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.47340644\n",
      "CPU times: user 3.91 s, sys: 2.63 s, total: 6.55 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(verbose=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "n = 10000\n",
    "X = train_features[:n]\n",
    "Y = train_targets[:n]\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    verbose = True, \n",
    "#     max_iter = 1\n",
    ")\n",
    "clf.partial_fit(X, Y, classes = np.unique(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd96dfb",
   "metadata": {},
   "source": [
    "# predicting on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f76effea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c27f8d3b7343808aea8c3d4e49ef5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_features = [vectorizer.transform(l) for l in tqdm(dev.sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73b712aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dd7dd9fdb04eabb8f4315b2a225f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_preds = [clf.predict_proba(f) for f in tqdm(dev_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7365e08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264918,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_targets = np.concatenate(dev.relevance.to_list())\n",
    "dev_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a248ec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264918,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds_flat = np.concatenate(dev_preds)[:, 1]\n",
    "dev_preds_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "292b3246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026500608650625878"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(dev_targets, dev_preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcb3c6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4177517408660397"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(dev_targets, dev_preds_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c79aa6",
   "metadata": {},
   "source": [
    "# saving to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95952a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jarobyte/scratch/malnis_dataset/words/predictions/test.pkl\", \"wb\") as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fed6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jarobyte/scratch/malnis_dataset/words/predictions/test.pkl\", \"rb\") as file:\n",
    "    clf_2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40595dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f224a63047d24b9aa9075368b2665ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_preds = [clf_2.predict_proba(f) for f in tqdm(dev_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd628d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264918,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds_flat = np.concatenate(dev_preds)[:, 1]\n",
    "dev_preds_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b72b6b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07870122614174122"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(dev_targets, dev_preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57bdcf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6871863337684786"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(dev_targets, dev_preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73757afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
