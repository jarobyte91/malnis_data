{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae054c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from malnis import show\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "# import scipy.sparse as sp\n",
    "# from sklearn.linear_model import LogisticRegression \n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.decomposition import PCA, SparsePCA\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import log_loss, PrecisionRecallDisplay, RocCurveDisplay\n",
    "import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import pytorch_lightning as pl\n",
    "# import torch.utils.data as tud\n",
    "# import seaborn as sns\n",
    "# sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d48d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8965, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>rl</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relevance</th>\n",
       "      <th>original_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We introduce a new language representation mod...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "      <td>[Our approach is mainly based on the BERT lang...</td>\n",
       "      <td>0.237885</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.229075</td>\n",
       "      <td>[KEYWORDS cascade ranking, pre-trained languag...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dominant sequence transduction models are ...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "      <td>[BERT [2] is a self-supervised approach for pr...</td>\n",
       "      <td>0.238372</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.215116</td>\n",
       "      <td>[KEYWORDS cascade ranking, pre-trained languag...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Language model pretraining has led to signific...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "      <td>[Recently, some variants [4, 12] of BERT langu...</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>[KEYWORDS cascade ranking, pre-trained languag...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the capability of modeling bidirectional ...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "      <td>[Recently, some variants [4, 12] of BERT langu...</td>\n",
       "      <td>0.237838</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.227027</td>\n",
       "      <td>[KEYWORDS cascade ranking, pre-trained languag...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural sequence-to-sequence models have provid...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "      <td>[The proposed model is based on the pointer-ge...</td>\n",
       "      <td>0.215139</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.199203</td>\n",
       "      <td>[KEYWORDS cascade ranking, pre-trained languag...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  We introduce a new language representation mod...   \n",
       "1  The dominant sequence transduction models are ...   \n",
       "2  Language model pretraining has led to signific...   \n",
       "3  With the capability of modeling bidirectional ...   \n",
       "4  Neural sequence-to-sequence models have provid...   \n",
       "\n",
       "                                            document  \\\n",
       "0  KEYWORDS cascade ranking, pre-trained language...   \n",
       "1  KEYWORDS cascade ranking, pre-trained language...   \n",
       "2  KEYWORDS cascade ranking, pre-trained language...   \n",
       "3  KEYWORDS cascade ranking, pre-trained language...   \n",
       "4  KEYWORDS cascade ranking, pre-trained language...   \n",
       "\n",
       "                                             summary        r1        r2  \\\n",
       "0  [Our approach is mainly based on the BERT lang...  0.237885  0.065359   \n",
       "1  [BERT [2] is a self-supervised approach for pr...  0.238372  0.063366   \n",
       "2  [Recently, some variants [4, 12] of BERT langu...  0.172727  0.047782   \n",
       "3  [Recently, some variants [4, 12] of BERT langu...  0.237838  0.078740   \n",
       "4  [The proposed model is based on the pointer-ge...  0.215139  0.093023   \n",
       "\n",
       "         rl                                          sentences  \\\n",
       "0  0.229075  [KEYWORDS cascade ranking, pre-trained languag...   \n",
       "1  0.215116  [KEYWORDS cascade ranking, pre-trained languag...   \n",
       "2  0.172727  [KEYWORDS cascade ranking, pre-trained languag...   \n",
       "3  0.227027  [KEYWORDS cascade ranking, pre-trained languag...   \n",
       "4  0.199203  [KEYWORDS cascade ranking, pre-trained languag...   \n",
       "\n",
       "                                           relevance  original_sentences  \n",
       "0  [False, False, False, False, False, False, Fal...                 117  \n",
       "1  [False, False, False, False, False, True, Fals...                 117  \n",
       "2  [False, False, False, False, False, True, Fals...                 117  \n",
       "3  [False, False, False, False, False, False, Tru...                 117  \n",
       "4  [False, False, False, False, False, False, Fal...                 117  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of sentences in each paper goes from 59 to 4,447. I truncate to 512.\n",
    "\n",
    "data = pd.read_pickle(\"../data/sentence_labels.pkl\")\\\n",
    ".reset_index(drop = True)\\\n",
    ".assign(original_sentences = lambda df: df.sentences.map(len))\\\n",
    ".assign(\n",
    "    sentences = lambda df: df.sentences.map(lambda y: y[:512]),\n",
    "    relevance = lambda df: df.relevance.map(lambda y: y[:512]),    \n",
    ")\n",
    "\n",
    "show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459f0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = \"/home/jarobyte/scratch/malnis_dataset/data/embeddings/specter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3590e0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8965, 512, 1536)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(embeddings_folder + \"X.npy\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc7178f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8965, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.load(embeddings_folder + \"Y.npy\")\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f8b580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (7172, 512, 1536)\n",
      "X_devtest (1793, 512, 1536)\n",
      "Y_train (7172, 512)\n",
      "Y_devtest (1793, 512)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    X_train, \n",
    "    X_devtest, \n",
    "    Y_train, \n",
    "    Y_devtest, \n",
    "    data_train, \n",
    "    data_devtest\n",
    ") = train_test_split(\n",
    "    X, \n",
    "    Y, \n",
    "    data, \n",
    "    random_state = 1,\n",
    "    test_size = 0.2\n",
    ")\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_devtest\", X_devtest.shape)\n",
    "print(\"Y_train\", Y_train.shape)\n",
    "print(\"Y_devtest\", Y_devtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8032be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev (896, 512, 1536)\n",
      "X_test (897, 512, 1536)\n",
      "Y_dev (896, 512)\n",
      "Y_test (897, 512)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    X_dev, \n",
    "    X_test, \n",
    "    Y_dev, \n",
    "    Y_test, \n",
    "    data_dev, \n",
    "    data_test\n",
    ") = train_test_split(\n",
    "    X_devtest, \n",
    "    Y_devtest, \n",
    "    data_devtest, \n",
    "    random_state = 1,\n",
    "    test_size = 0.5\n",
    ")\n",
    "print(\"X_dev\", X_dev.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"Y_dev\", Y_dev.shape)\n",
    "print(\"Y_test\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b75dd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folder = \"/home/jarobyte/scratch/malnis_dataset/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f80da78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train saved in /home/jarobyte/scratch/malnis_dataset/data/X_train.npy\n",
      "X_dev saved in /home/jarobyte/scratch/malnis_dataset/data/X_dev.npy\n",
      "X_test saved in /home/jarobyte/scratch/malnis_dataset/data/X_test.npy\n",
      "Y_train saved in /home/jarobyte/scratch/malnis_dataset/data/Y_train.npy\n",
      "Y_dev saved in /home/jarobyte/scratch/malnis_dataset/data/Y_dev.npy\n",
      "Y_test saved in /home/jarobyte/scratch/malnis_dataset/data/Y_test.npy\n"
     ]
    }
   ],
   "source": [
    "to_write = [\n",
    "    (\"X_train\", X_train),\n",
    "    (\"X_dev\", X_dev),\n",
    "    (\"X_test\", X_test),\n",
    "    \n",
    "    (\"Y_train\", Y_train),\n",
    "    (\"Y_dev\", Y_dev),\n",
    "    (\"Y_test\", Y_test),\n",
    "]\n",
    "\n",
    "for name, contents in to_write:\n",
    "#     contents = contents.cpu().numpy()\n",
    "    path = split_folder + name + \".npy\"\n",
    "    np.save(path, contents)\n",
    "    print(name, \"saved in\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee1199dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train saved in /home/jarobyte/scratch/malnis_dataset/data/data_train.pkl\n",
      "data_dev saved in /home/jarobyte/scratch/malnis_dataset/data/data_dev.pkl\n",
      "data_test saved in /home/jarobyte/scratch/malnis_dataset/data/data_test.pkl\n"
     ]
    }
   ],
   "source": [
    "to_write = [\n",
    "    (\"data_train\", data_train),\n",
    "    (\"data_dev\", data_dev),\n",
    "    (\"data_test\", data_test),\n",
    "]\n",
    "\n",
    "for name, contents in to_write:\n",
    "#     contents = contents.cpu().numpy()\n",
    "    path = split_folder + name + \".pkl\"\n",
    "    contents.to_pickle(path)\n",
    "    print(name, \"saved in\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f4740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
