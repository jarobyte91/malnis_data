{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "980dfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from malnis import show\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07ce839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>query</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[29, R425–R473 Forum Using Soundscapes to Asse...</td>\n",
       "      <td>Hydrothermal vents are unique deep-sea structu...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Therefore, using daily SEL to describe sounds...</td>\n",
       "      <td>Hydrothermal vents are unique deep-sea structu...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[TECHNOLOGY AND CODE published: 19 August 2021...</td>\n",
       "      <td>Hydrothermal vents are unique deep-sea structu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ORIGINAL RESEARCH published: 05 August 2021 d...</td>\n",
       "      <td>Hydrothermal vents are unique deep-sea structu...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A brief overview of current approaches for un...</td>\n",
       "      <td>Hydrothermal vents are unique deep-sea structu...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Due to its tremendous advantages this technol...</td>\n",
       "      <td>Cloud computing provides a shared pool of comp...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Interpretable &amp; Explorable Approximations of ...</td>\n",
       "      <td>Prognostic modelling using machine learning te...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Introduction Over the past decade, there has ...</td>\n",
       "      <td>Prognostic modelling using machine learning te...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[To gain insight into the black-box model, we ...</td>\n",
       "      <td>Prognostic modelling using machine learning te...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Next, three techniques, Bayesian networks, Lo...</td>\n",
       "      <td>Obesity is a significant problem in population...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Finally, a software was built to use and trai...</td>\n",
       "      <td>Obesity is a significant problem in population...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[International Conference on Advances in Compu...</td>\n",
       "      <td>A Scenario-based Trust management\\nApproach wi...</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[This is what gives the VANET a high level of ...</td>\n",
       "      <td>A Scenario-based Trust management\\nApproach wi...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[The proposed framework is expected to improve...</td>\n",
       "      <td>A Scenario-based Trust management\\nApproach wi...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[VANET provides safety and traffic analysis me...</td>\n",
       "      <td>A Scenario-based Trust management\\nApproach wi...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[A video event detection system usually consis...</td>\n",
       "      <td>Video Captioning is a task of automatic captio...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[To approach this problem, we propose a novel ...</td>\n",
       "      <td>Video Captioning is a task of automatic captio...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[Participating teams built language topic mode...</td>\n",
       "      <td>Current methods of assessing dementia Alzheime...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[Our approach is based on the character n-gram...</td>\n",
       "      <td>Current methods of assessing dementia Alzheime...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[Character n-gram based methods have been succ...</td>\n",
       "      <td>Current methods of assessing dementia Alzheime...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[9 RELATED WORK Several major solutions were p...</td>\n",
       "      <td>In recent years, we have seen a surge on the n...</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[Since we have provided two platforms to the u...</td>\n",
       "      <td>In recent years, we have seen a surge on the n...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[Consequently, a number of distributed stream ...</td>\n",
       "      <td>In recent years, we have seen a surge on the n...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   [29, R425–R473 Forum Using Soundscapes to Asse...   \n",
       "1   [Therefore, using daily SEL to describe sounds...   \n",
       "2   [TECHNOLOGY AND CODE published: 19 August 2021...   \n",
       "3   [ORIGINAL RESEARCH published: 05 August 2021 d...   \n",
       "4   [A brief overview of current approaches for un...   \n",
       "5   [Due to its tremendous advantages this technol...   \n",
       "6   [Interpretable & Explorable Approximations of ...   \n",
       "7   [Introduction Over the past decade, there has ...   \n",
       "9   [To gain insight into the black-box model, we ...   \n",
       "11  [Next, three techniques, Bayesian networks, Lo...   \n",
       "12  [Finally, a software was built to use and trai...   \n",
       "16  [International Conference on Advances in Compu...   \n",
       "17  [This is what gives the VANET a high level of ...   \n",
       "18  [The proposed framework is expected to improve...   \n",
       "19  [VANET provides safety and traffic analysis me...   \n",
       "20  [A video event detection system usually consis...   \n",
       "21  [To approach this problem, we propose a novel ...   \n",
       "22  [Participating teams built language topic mode...   \n",
       "23  [Our approach is based on the character n-gram...   \n",
       "24  [Character n-gram based methods have been succ...   \n",
       "25  [9 RELATED WORK Several major solutions were p...   \n",
       "26  [Since we have provided two platforms to the u...   \n",
       "27  [Consequently, a number of distributed stream ...   \n",
       "\n",
       "                                                query  \\\n",
       "0   Hydrothermal vents are unique deep-sea structu...   \n",
       "1   Hydrothermal vents are unique deep-sea structu...   \n",
       "2   Hydrothermal vents are unique deep-sea structu...   \n",
       "3   Hydrothermal vents are unique deep-sea structu...   \n",
       "4   Hydrothermal vents are unique deep-sea structu...   \n",
       "5   Cloud computing provides a shared pool of comp...   \n",
       "6   Prognostic modelling using machine learning te...   \n",
       "7   Prognostic modelling using machine learning te...   \n",
       "9   Prognostic modelling using machine learning te...   \n",
       "11  Obesity is a significant problem in population...   \n",
       "12  Obesity is a significant problem in population...   \n",
       "16  A Scenario-based Trust management\\nApproach wi...   \n",
       "17  A Scenario-based Trust management\\nApproach wi...   \n",
       "18  A Scenario-based Trust management\\nApproach wi...   \n",
       "19  A Scenario-based Trust management\\nApproach wi...   \n",
       "20  Video Captioning is a task of automatic captio...   \n",
       "21  Video Captioning is a task of automatic captio...   \n",
       "22  Current methods of assessing dementia Alzheime...   \n",
       "23  Current methods of assessing dementia Alzheime...   \n",
       "24  Current methods of assessing dementia Alzheime...   \n",
       "25  In recent years, we have seen a surge on the n...   \n",
       "26  In recent years, we have seen a surge on the n...   \n",
       "27  In recent years, we have seen a surge on the n...   \n",
       "\n",
       "                                            relevance  \n",
       "0       [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1   [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "2   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3   [0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, ...  \n",
       "4   [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, ...  \n",
       "5       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]  \n",
       "6                                  [1, 0, 1, 0, 1, 0]  \n",
       "7                            [1, 1, 1, 0, 1, 1, 0, 0]  \n",
       "9                [1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1]  \n",
       "11                        [1, 1, 1, 0, 0, 0, 1, 1, 0]  \n",
       "12                                 [1, 1, 0, 1, 0, 1]  \n",
       "16                                          [0, 1, 0]  \n",
       "17                                             [1, 0]  \n",
       "18                              [1, 1, 1, 1, 1, 0, 0]  \n",
       "19                                          [1, 0, 0]  \n",
       "20                                             [0, 1]  \n",
       "21  [0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, ...  \n",
       "22         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "23                                             [1, 0]  \n",
       "24                                       [1, 0, 0, 0]  \n",
       "25                                          [0, 1, 0]  \n",
       "26                                 [0, 0, 1, 1, 0, 0]  \n",
       "27                                 [0, 1, 1, 0, 0, 0]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"quotes.pkl\")\n",
    "show(data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06cbb7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7172, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>rl</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relevance</th>\n",
       "      <th>original_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>Due to the lack of structured knowledge applie...</td>\n",
       "      <td>Index Terms—Machine learning, knowledge discov...</td>\n",
       "      <td>[Text classification [226], text clustering [2...</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.095941</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>[Index Terms—Machine learning, knowledge disco...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7554</th>\n",
       "      <td>Obtaining enough labeled data to robustly trai...</td>\n",
       "      <td>One of the greatest roadblocks to using modern...</td>\n",
       "      <td>[“Lawyer”); moreover, these sources might be c...</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.104247</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>[One of the greatest roadblocks to using moder...</td>\n",
       "      <td>[True, False, True, False, False, False, False...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>Word embeddings, i.e., low-dimensional vector ...</td>\n",
       "      <td>Recently some studies have shown that text cla...</td>\n",
       "      <td>[A recent work (Schuster et al., 2020) showed ...</td>\n",
       "      <td>0.407018</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>[Recently some studies have shown that text cl...</td>\n",
       "      <td>[False, False, True, False, False, False, Fals...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>In this paper our objectives are, first, netwo...</td>\n",
       "      <td>It is commonsense that how you look at an obje...</td>\n",
       "      <td>[Views are commonly different sensory signals,...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[It is commonsense that how you look at an obj...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>This paper describes TextTiling, an algorithm ...</td>\n",
       "      <td>Accurately representing the distance between t...</td>\n",
       "      <td>[Most similar to our method is that of Wan (20...</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>[Accurately representing the distance between ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "7593  Due to the lack of structured knowledge applie...   \n",
       "7554  Obtaining enough labeled data to robustly trai...   \n",
       "4892  Word embeddings, i.e., low-dimensional vector ...   \n",
       "4169  In this paper our objectives are, first, netwo...   \n",
       "6690  This paper describes TextTiling, an algorithm ...   \n",
       "\n",
       "                                               document  \\\n",
       "7593  Index Terms—Machine learning, knowledge discov...   \n",
       "7554  One of the greatest roadblocks to using modern...   \n",
       "4892  Recently some studies have shown that text cla...   \n",
       "4169  It is commonsense that how you look at an obje...   \n",
       "6690  Accurately representing the distance between t...   \n",
       "\n",
       "                                                summary        r1        r2  \\\n",
       "7593  [Text classification [226], text clustering [2...  0.278846  0.095941   \n",
       "7554  [“Lawyer”); moreover, these sources might be c...  0.295455  0.104247   \n",
       "4892  [A recent work (Schuster et al., 2020) showed ...  0.407018  0.186364   \n",
       "4169  [Views are commonly different sensory signals,...  0.257143  0.090909   \n",
       "6690  [Most similar to our method is that of Wan (20...  0.206349  0.037975   \n",
       "\n",
       "            rl                                          sentences  \\\n",
       "7593  0.259615  [Index Terms—Machine learning, knowledge disco...   \n",
       "7554  0.272727  [One of the greatest roadblocks to using moder...   \n",
       "4892  0.385965  [Recently some studies have shown that text cl...   \n",
       "4169  0.250000  [It is commonsense that how you look at an obj...   \n",
       "6690  0.158730  [Accurately representing the distance between ...   \n",
       "\n",
       "                                              relevance  original_sentences  \n",
       "7593  [False, False, False, False, False, False, Fal...                 685  \n",
       "7554  [True, False, True, False, False, False, False...                 246  \n",
       "4892  [False, False, True, False, False, False, Fals...                 202  \n",
       "4169  [False, False, False, False, False, False, Fal...                 240  \n",
       "6690  [False, False, False, False, False, False, Fal...                 246  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle(\"/home/jarobyte/scratch/malnis_dataset/data/data_train.pkl\")\n",
    "show(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abecaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e6294",
   "metadata": {},
   "source": [
    "# classical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d71d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2089747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "corpus = train.sentences.sum()\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be307770",
   "metadata": {},
   "source": [
    "## words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2963388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    analyzer = \"word\",\n",
    "    ngram_range = (1, 1)\n",
    ")\n",
    "word_vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ae31d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = data.text.map(word_vectorizer.transform)\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8350d004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_queries = data[\"query\"].map(lambda x: word_vectorizer.transform([x]))\n",
    "len(word_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f72fe",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae96eee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_scores = [(f @ q.T).toarray().squeeze() for f, q in zip(word_features, word_queries)]\n",
    "len(word_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6a5a57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22349912, 0.26112057, 0.46502043, 0.04701891, 0.05946417,\n",
       "       0.32419993, 0.16290082, 0.30282736, 0.2951947 , 0.17113323,\n",
       "       0.27721748, 0.31616401, 0.39206688, 0.05603763, 0.07432639])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd3866da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ap = [average_precision_score(l, s) for l, s in zip(tqdm(data.relevance), word_scores)]\n",
    "len(word_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e47d0c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ra = [roc_auc_score(l, s) for l, s in zip(tqdm(data.relevance), word_scores)]\n",
    "len(word_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "850ceca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'tfidf_words',\n",
       "  'ap_mean': 0.5753637004394068,\n",
       "  'ap_std': 0.11248102455922193,\n",
       "  'ra_mean': 0.5425925714488694,\n",
       "  'ra_std': 0.1312144617891538}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.append(\n",
    "    dict(\n",
    "        model = \"tfidf_words\",\n",
    "        ap_mean = np.mean(word_ap), \n",
    "        ap_std = 2 * np.std(word_ap)/np.sqrt(len(word_ap)),\n",
    "        ra_mean = np.mean(word_ra), \n",
    "        ra_std = 2 * np.std(word_ra)/np.sqrt(len(word_ra))\n",
    "    )\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047993dd",
   "metadata": {},
   "source": [
    "## mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ded35cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jarobyte/scratch/malnis_dataset/mlp_tfidf/words/models/15010241_7.pkl\", \"rb\") as file:\n",
    "    mlp_words = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e77eca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mlp_scores = [mlp_words.predict_proba(x)[:, 1] for x in word_features]\n",
    "len(word_mlp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae42e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mlp_ap = [average_precision_score(l, s) for l, s in zip(tqdm(data.relevance), word_mlp_scores)]\n",
    "len(word_mlp_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b821ffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mlp_ra = [roc_auc_score(l, s) for l, s in zip(tqdm(data.relevance), word_mlp_scores)]\n",
    "len(word_mlp_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd685394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'tfidf_words',\n",
       "  'ap_mean': 0.5753637004394068,\n",
       "  'ap_std': 0.11248102455922193,\n",
       "  'ra_mean': 0.5425925714488694,\n",
       "  'ra_std': 0.1312144617891538},\n",
       " {'model': 'mlp_words',\n",
       "  'ap_mean': 0.6542930633091931,\n",
       "  'ap_std': 0.12689653830649794,\n",
       "  'ra_mean': 0.6504883219756941,\n",
       "  'ra_std': 0.13484475623274275}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.append(\n",
    "    dict(\n",
    "        model = \"mlp_words\",\n",
    "        ap_mean = np.mean(word_mlp_ap), \n",
    "        ap_std = 2 * np.std(word_mlp_ap)/np.sqrt(len(word_mlp_ap)),\n",
    "        ra_mean = np.mean(word_mlp_ra), \n",
    "        ra_std = 2 * np.std(word_mlp_ra)/np.sqrt(len(word_mlp_ra))\n",
    "    )\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ced5ae",
   "metadata": {},
   "source": [
    "## chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0396e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(3, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(3, 3))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(3, 3))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer = \"char\",\n",
    "    ngram_range = (3, 3)\n",
    ")\n",
    "char_vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "728a635a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_features = data.text.map(char_vectorizer.transform)\n",
    "len(char_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f387378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_queries = data[\"query\"].map(lambda x: char_vectorizer.transform([x]))\n",
    "len(char_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b1265",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e742995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_scores = [(f @ q.T).toarray().squeeze() for f, q in zip(char_features, char_queries)]\n",
    "len(char_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f464ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27963787, 0.2435618 , 0.29566185, 0.36901626, 0.18608043,\n",
       "       0.39333694, 0.28094598, 0.29278575, 0.24565227, 0.28015445,\n",
       "       0.20125509, 0.37141184, 0.23642442, 0.08147654, 0.09050535])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66126d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7023f3ec3b443a7b6380b63f0dc0ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_ap = [average_precision_score(l, s) for l, s in zip(tqdm(data.relevance), char_scores)]\n",
    "len(char_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6486b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f1d8362aab419184e97b4ac7a665a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_ra = [roc_auc_score(l, s) for l, s in zip(tqdm(data.relevance), char_scores)]\n",
    "len(char_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1cfe06b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'tfidf_words',\n",
       "  'ap_mean': 0.5753637004394068,\n",
       "  'ap_std': 0.11248102455922193,\n",
       "  'ra_mean': 0.5425925714488694,\n",
       "  'ra_std': 0.1312144617891538},\n",
       " {'model': 'mlp_words',\n",
       "  'ap_mean': 0.6542930633091931,\n",
       "  'ap_std': 0.12689653830649794,\n",
       "  'ra_mean': 0.6504883219756941,\n",
       "  'ra_std': 0.13484475623274275},\n",
       " {'model': 'tfidf_chars',\n",
       "  'ap_mean': 0.6743565420052174,\n",
       "  'ap_std': 0.10458764962687674,\n",
       "  'ra_mean': 0.6343831537885246,\n",
       "  'ra_std': 0.13090523765556375}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.append(\n",
    "    dict(\n",
    "        model = \"tfidf_chars\",\n",
    "        ap_mean = np.mean(char_ap), \n",
    "        ap_std = 2 * np.std(char_ap)/np.sqrt(len(char_ap)),\n",
    "        ra_mean = np.mean(char_ra), \n",
    "        ra_std = 2 * np.std(char_ra)/np.sqrt(len(char_ra))\n",
    "    )\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3b16a",
   "metadata": {},
   "source": [
    "## mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92880407",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jarobyte/scratch/malnis_dataset/mlp_tfidf/chars/models/14986643_2.pkl\", \"rb\") as file:\n",
    "    mlp_chars = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7eca27be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_mlp_scores = [mlp_chars.predict_proba(x)[:, 1] for x in char_features]\n",
    "len(char_mlp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21051956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c80de5352a46d0a4706aa49a2ee710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_mlp_ap = [average_precision_score(l, s) for l, s in zip(tqdm(data.relevance), char_mlp_scores)]\n",
    "len(char_mlp_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "266b17e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc6578777a441d2a0419936ad9df0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_mlp_ra = [roc_auc_score(l, s) for l, s in zip(tqdm(data.relevance), char_mlp_scores)]\n",
    "len(char_mlp_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2410f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'tfidf_words',\n",
       "  'ap_mean': 0.5753637004394068,\n",
       "  'ap_std': 0.11248102455922193,\n",
       "  'ra_mean': 0.5425925714488694,\n",
       "  'ra_std': 0.1312144617891538},\n",
       " {'model': 'mlp_words',\n",
       "  'ap_mean': 0.6542930633091931,\n",
       "  'ap_std': 0.12689653830649794,\n",
       "  'ra_mean': 0.6504883219756941,\n",
       "  'ra_std': 0.13484475623274275},\n",
       " {'model': 'tfidf_chars',\n",
       "  'ap_mean': 0.6743565420052174,\n",
       "  'ap_std': 0.10458764962687674,\n",
       "  'ra_mean': 0.6343831537885246,\n",
       "  'ra_std': 0.13090523765556375},\n",
       " {'model': 'mlp_chars',\n",
       "  'ap_mean': 0.6644389816679619,\n",
       "  'ap_std': 0.13069853702216494,\n",
       "  'ra_mean': 0.6819279927056462,\n",
       "  'ra_std': 0.1151384827842618}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.append(\n",
    "    dict(\n",
    "        model = \"mlp_chars\",\n",
    "        ap_mean = np.mean(char_mlp_ap), \n",
    "        ap_std = 2 * np.std(char_mlp_ap)/np.sqrt(len(char_mlp_ap)),\n",
    "        ra_mean = np.mean(char_mlp_ra), \n",
    "        ra_std = 2 * np.std(char_mlp_ra)/np.sqrt(len(char_mlp_ra))\n",
    "    )\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6342805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ap_mean</th>\n",
       "      <th>ap_std</th>\n",
       "      <th>ra_mean</th>\n",
       "      <th>ra_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_words</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>0.542593</td>\n",
       "      <td>0.131214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp_words</td>\n",
       "      <td>0.654293</td>\n",
       "      <td>0.126897</td>\n",
       "      <td>0.650488</td>\n",
       "      <td>0.134845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_chars</td>\n",
       "      <td>0.674357</td>\n",
       "      <td>0.104588</td>\n",
       "      <td>0.634383</td>\n",
       "      <td>0.130905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp_chars</td>\n",
       "      <td>0.664439</td>\n",
       "      <td>0.130699</td>\n",
       "      <td>0.681928</td>\n",
       "      <td>0.115138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model   ap_mean    ap_std   ra_mean    ra_std\n",
       "0  tfidf_words  0.575364  0.112481  0.542593  0.131214\n",
       "1    mlp_words  0.654293  0.126897  0.650488  0.134845\n",
       "2  tfidf_chars  0.674357  0.104588  0.634383  0.130905\n",
       "3    mlp_chars  0.664439  0.130699  0.681928  0.115138"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "show(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3a09724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &        model &  ap\\_mean &  ap\\_std &  ra\\_mean &  ra\\_std \\\\\n",
      "\\midrule\n",
      "0 &  tfidf\\_words &    0.575 &   0.112 &    0.543 &   0.131 \\\\\n",
      "1 &    mlp\\_words &    0.654 &   0.127 &    0.650 &   0.135 \\\\\n",
      "2 &  tfidf\\_chars &    0.674 &   0.105 &    0.634 &   0.131 \\\\\n",
      "3 &    mlp\\_chars &    0.664 &   0.131 &    0.682 &   0.115 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888692/2842510611.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.round(3).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(results_df.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a11be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(\"quotes_results_classical.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
