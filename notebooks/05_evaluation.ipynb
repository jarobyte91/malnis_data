{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "364064ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from malnis import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0a623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253cb0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = os.listdir(folder)\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e77de6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [np.load(folder + \"/\" + m) for m in names]\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2645336e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(646033,), (646033,), (646033,), (646033,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e95872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.8222738e-06, 0.0, -0.20886487]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.min() for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "144b34ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7348571074013805, 0.23949808, 0.7314921631927598, 0.871394]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.max() for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdbcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"../data/split/labels_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d552ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets (646033,)\n"
     ]
    }
   ],
   "source": [
    "targets = np.concatenate(test.relevance.to_list())\n",
    "print(\"targets\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f0c50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>predictions</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_words</td>\n",
       "      <td>[0.17679966650065002, 0.0, 0.04196174263528449...</td>\n",
       "      <td>0.133881</td>\n",
       "      <td>0.776791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm_test</td>\n",
       "      <td>[0.03985972, 0.008530628, 0.04972529, 0.044483...</td>\n",
       "      <td>0.067441</td>\n",
       "      <td>0.675732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_chars</td>\n",
       "      <td>[0.17949374164076828, 0.0, 0.12743852765181915...</td>\n",
       "      <td>0.096032</td>\n",
       "      <td>0.712048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence_bert</td>\n",
       "      <td>[0.5600614, 0.04071678, 0.39229715, 0.46493974...</td>\n",
       "      <td>0.067186</td>\n",
       "      <td>0.637246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                        predictions  \\\n",
       "0    tfidf_words  [0.17679966650065002, 0.0, 0.04196174263528449...   \n",
       "1      lstm_test  [0.03985972, 0.008530628, 0.04972529, 0.044483...   \n",
       "2    tfidf_chars  [0.17949374164076828, 0.0, 0.12743852765181915...   \n",
       "3  sentence_bert  [0.5600614, 0.04071678, 0.39229715, 0.46493974...   \n",
       "\n",
       "   average_precision   roc_auc  \n",
       "0           0.133881  0.776791  \n",
       "1           0.067441  0.675732  \n",
       "2           0.096032  0.712048  \n",
       "3           0.067186  0.637246  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"name\":names, \"predictions\":predictions})\\\n",
    ".assign(\n",
    "    name = lambda df: df.name.map(lambda x: x[:-4]),\n",
    "    average_precision = lambda df: df.predictions.map(lambda x: average_precision_score(targets, x)),\n",
    "    roc_auc = lambda df: df.predictions.map(lambda x: roc_auc_score(targets, x))\n",
    ")\\\n",
    "# .drop(columns = \"predictions\")\n",
    "\n",
    "show(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
