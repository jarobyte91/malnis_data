{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc12403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import PunktSentenceTokenizer, word_tokenize\n",
    "from nltk.metrics import distance\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45786108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(x):\n",
    "    print(x.shape)\n",
    "    return x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcc3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56746, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>internal_reference_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>context</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Our approach is mainly based on the BERT langu...</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>444</td>\n",
       "      <td>Different from many other ranking methods whic...</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "      <td>Moreover, for full ranking subtask, we use a s...</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>The proposed model is based on the pointer-gen...</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>Following [7], we also use a soft switch to ch...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  internal_reference_id  reference_id  \\\n",
       "0         0                      1             1   \n",
       "1         0                      8           444   \n",
       "2         0                      5           163   \n",
       "3         0                      6            26   \n",
       "4         0                      6            26   \n",
       "\n",
       "                                             context  start_offset  end_offset  \n",
       "0  Our approach is mainly based on the BERT langu...            56          59  \n",
       "1  Different from many other ranking methods whic...           216         219  \n",
       "2  Moreover, for full ranking subtask, we use a s...            78          81  \n",
       "3  The proposed model is based on the pointer-gen...            59          62  \n",
       "4  Following [7], we also use a soft switch to ch...            10          13  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations = pd.read_csv(\"../data/citations.csv\")\n",
    "show(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087fd6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24921, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_citations</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Distributed Representations of Words and Phras...</td>\n",
       "      <td>172</td>\n",
       "      <td>The recently introduced continuous Skip-gram m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BERT: Pre-training of Deep Bidirectional Trans...</td>\n",
       "      <td>167</td>\n",
       "      <td>We introduce a new language representation mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Attention Is All You Need</td>\n",
       "      <td>155</td>\n",
       "      <td>The dominant sequence transduction models are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GloVe : Global Vectors for Word Representation</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adam: A Method for Stochastic Optimization</td>\n",
       "      <td>123</td>\n",
       "      <td>We introduce Adam, an algorithm for first-orde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_id                                              title  \\\n",
       "0             0  Distributed Representations of Words and Phras...   \n",
       "1             1  BERT: Pre-training of Deep Bidirectional Trans...   \n",
       "2             2                          Attention Is All You Need   \n",
       "3             3     GloVe : Global Vectors for Word Representation   \n",
       "4             4         Adam: A Method for Stochastic Optimization   \n",
       "\n",
       "   original_citations                                           abstract  \n",
       "0                 172  The recently introduced continuous Skip-gram m...  \n",
       "1                 167  We introduce a new language representation mod...  \n",
       "2                 155  The dominant sequence transduction models are ...  \n",
       "3                 154                                                NaN  \n",
       "4                 123  We introduce Adam, an algorithm for first-orde...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = pd.read_csv(\"../data/references.csv\")\n",
    "show(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2bd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1091, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>IDST at TREC 2019 Deep Learning Track: Deep Ca...</td>\n",
       "      <td>This paper describes our participation in the ...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BatchBALD: Efficient and Diverse Batch Acquisi...</td>\n",
       "      <td>We develop BatchBALD, a tractable approximatio...</td>\n",
       "      <td>A key problem in deep learning is data efficie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A Sentence Compression Based Framework to Quer...</td>\n",
       "      <td>We consider the problem of using sentence comp...</td>\n",
       "      <td>Proceedings of the 51st Annual Meeting of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DR-BiLSTM: Dependent Reading Bidirectional LST...</td>\n",
       "      <td>We present a novel deep learning architecture ...</td>\n",
       "      <td>Natural Language Inference (NLI; a.k.a. Recogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>On Minimizing Cost in Legal Document ReviewWor...</td>\n",
       "      <td>Technology-assisted review (TAR) refers to hum...</td>\n",
       "      <td>CCS CONCEPTS • Information systems → Informati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                              title  \\\n",
       "0         0  IDST at TREC 2019 Deep Learning Track: Deep Ca...   \n",
       "1         1  BatchBALD: Efficient and Diverse Batch Acquisi...   \n",
       "2         2  A Sentence Compression Based Framework to Quer...   \n",
       "3         3  DR-BiLSTM: Dependent Reading Bidirectional LST...   \n",
       "4         4  On Minimizing Cost in Legal Document ReviewWor...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This paper describes our participation in the ...   \n",
       "1  We develop BatchBALD, a tractable approximatio...   \n",
       "2  We consider the problem of using sentence comp...   \n",
       "3  We present a novel deep learning architecture ...   \n",
       "4  Technology-assisted review (TAR) refers to hum...   \n",
       "\n",
       "                                                text  \n",
       "0  KEYWORDS cascade ranking, pre-trained language...  \n",
       "1  A key problem in deep learning is data efficie...  \n",
       "2  Proceedings of the 51st Annual Meeting of the ...  \n",
       "3  Natural Language Inference (NLI; a.k.a. Recogn...  \n",
       "4  CCS CONCEPTS • Information systems → Informati...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv(\"../data/papers.csv\")\n",
    "show(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd53df",
   "metadata": {},
   "source": [
    "# most mentioned papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a73b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>906</td>\n",
       "      <td>5990</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>1857</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>744</td>\n",
       "      <td>2729</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1062</td>\n",
       "      <td>174</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>482</td>\n",
       "      <td>1182</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>647</td>\n",
       "      <td>1182</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>482</td>\n",
       "      <td>1899</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>647</td>\n",
       "      <td>1899</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>476</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>995</td>\n",
       "      <td>23051</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>372</td>\n",
       "      <td>1182</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>560</td>\n",
       "      <td>2473</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>476</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>311</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>850</td>\n",
       "      <td>3129</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>959</td>\n",
       "      <td>160</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>24263</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>752</td>\n",
       "      <td>1407</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>807</td>\n",
       "      <td>15388</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id  reference_id  mentions\n",
       "0        906          5990       105\n",
       "1        713          1857        51\n",
       "2        744          2729        42\n",
       "3       1062           174        41\n",
       "4        476            26        34\n",
       "5        482          1182        30\n",
       "6        647          1182        30\n",
       "7        482          1899        28\n",
       "8        647          1899        28\n",
       "9        476            47        27\n",
       "10       995         23051        27\n",
       "11       372          1182        26\n",
       "12       560          2473        26\n",
       "13       476            45        25\n",
       "14       311            72        25\n",
       "15       850          3129        23\n",
       "16       959           160        23\n",
       "17        80         24263        22\n",
       "18       752          1407        22\n",
       "19       807         15388        22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations.groupby([\"paper_id\", \"reference_id\"]).size()\\\n",
    ".sort_values(ascending = False)\\\n",
    ".rename(\"mentions\")\\\n",
    ".reset_index()\\\n",
    ".head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d104d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reference_id  mentions\n",
       "0              0        14\n",
       "1              1        16\n",
       "2              2         7\n",
       "3              3        10\n",
       "4              4         4\n",
       "5              5         5\n",
       "6              6         8\n",
       "7              7         7\n",
       "8              8        10\n",
       "9              9         6\n",
       "10            10         7\n",
       "11            11         7\n",
       "12            12         3\n",
       "13            13         5\n",
       "14            14         6\n",
       "15            15         7\n",
       "16            16         5\n",
       "17            17         5\n",
       "18            18         5\n",
       "19            19         7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations.groupby([\"reference_id\", \"paper_id\"]).size()\\\n",
    ".rename(\"mentions\")\\\n",
    ".reset_index()\\\n",
    ".sort_values(\"mentions\", ascending = False)\\\n",
    ".groupby(\"reference_id\")\\\n",
    ".mentions.max()\\\n",
    ".head(20)\\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db0005d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>482</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>817</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1031</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>302</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1031</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>380</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1031</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>722</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>979</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>926</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>213</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>715</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>217</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>578</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>482</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reference_id  paper_id  mentions\n",
       "0              0        84        14\n",
       "1              1       482        16\n",
       "2              2       817         7\n",
       "3              3      1031        10\n",
       "4              4       302         4\n",
       "5              5       405         5\n",
       "6              6      1031         8\n",
       "7              7       380         7\n",
       "8              8      1031        10\n",
       "9              9       722         6\n",
       "10            10       979         7\n",
       "11            11       926         7\n",
       "12            12       213         3\n",
       "13            13        38         5\n",
       "14            14       715         6\n",
       "15            15       217         7\n",
       "16            16       578         5\n",
       "17            17        14         5\n",
       "18            18       482         5\n",
       "19            19        12         7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_pool = citations.groupby([\"reference_id\", \"paper_id\"]).size()\\\n",
    ".rename(\"mentions\")\\\n",
    ".reset_index()\\\n",
    ".sort_values(\"mentions\", ascending = False)\\\n",
    ".groupby(\"reference_id\")\\\n",
    ".first()\\\n",
    ".head(20)\\\n",
    ".reset_index()\n",
    "\n",
    "task_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bbf7e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_pool.mentions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821deff1",
   "metadata": {},
   "source": [
    "#  training sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8317cc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43990351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.text.map(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717d4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 34.4 s, total: 2min 18s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = PunktSentenceTokenizer(papers.text.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e53d2",
   "metadata": {},
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552baa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27140, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_id  paper_id  sentence                                      text  \\\n",
       "0             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "0             0        84         1                                         .   \n",
       "0             0        84         2                                         .   \n",
       "0             0        84         3                                         .   \n",
       "0             0        84         4                                         .   \n",
       "\n",
       "                                     sentence_words  \n",
       "0  [List, of, Abbreviations, and, Symbols, Used, .]  \n",
       "0                                               [.]  \n",
       "0                                               [.]  \n",
       "0                                               [.]  \n",
       "0                                               [.]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_sentences = task_pool.merge(papers[[\"paper_id\", \"text\"]])\\\n",
    ".assign(\n",
    "    sentences = lambda df: df.text.map(\n",
    "        lambda x: list(enumerate(tokenizer.tokenize(x)))\n",
    "    )\n",
    ")\\\n",
    ".assign(n_sentences = lambda df: df.sentences.map(len))\\\n",
    ".sort_values(\"reference_id\")\\\n",
    ".explode(\"sentences\")\\\n",
    ".drop(columns = \"text\")\\\n",
    ".assign(\n",
    "    sentence = lambda df: df.sentences.map(lambda x: x[0]),\n",
    "    text = lambda df: df.sentences.map(lambda x: x[1]),\n",
    "    sentence_words = lambda df: df.sentences.map(\n",
    "        lambda x: word_tokenize(x[1])\n",
    "    )\n",
    ")\\\n",
    ".drop(columns = [\"sentences\", \"n_sentences\", \"mentions\"])\n",
    "\n",
    "show(task_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5891dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>citation_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[Regarding, textual, context, ,, we, evaluated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[Within, Distributional, methods, ,, we, intro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_id  paper_id                                     citation_words\n",
       "0             0        84  [Regarding, textual, context, ,, we, evaluated...\n",
       "1             0        84  [Evaluating, the, recent, dense, word, embeddi...\n",
       "2             0        84  [Evaluating, the, recent, dense, word, embeddi...\n",
       "3             0        84  [2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...\n",
       "4             0        84  [Within, Distributional, methods, ,, we, intro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_citations = task_pool.merge(citations)\\\n",
    ".assign(citation_words = lambda df: df.context.map(word_tokenize))\\\n",
    "[[\"reference_id\", \"paper_id\", \"citation_words\"]]\n",
    "\n",
    "show(task_citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a62d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271295, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "      <th>citation_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Regarding, textual, context, ,, we, evaluated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Within, Distributional, methods, ,, we, intro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_id  paper_id  sentence                                      text  \\\n",
       "0             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "1             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "2             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "3             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "4             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "\n",
       "                                     sentence_words  \\\n",
       "0  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "1  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "2  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "3  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "4  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "\n",
       "                                      citation_words  \n",
       "0  [Regarding, textual, context, ,, we, evaluated...  \n",
       "1  [Evaluating, the, recent, dense, word, embeddi...  \n",
       "2  [Evaluating, the, recent, dense, word, embeddi...  \n",
       "3  [2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...  \n",
       "4  [Within, Distributional, methods, ,, we, intro...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation = task_sentences.merge(task_citations)\n",
    "\n",
    "show(sentence_citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148d9c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf69f458afe24175aa5cc0858a3b126e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/271295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = [distance.edit_distance(a, b) for a, b in tqdm(sentence_citation[[\"sentence_words\", \"citation_words\"]].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929a0ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(distances, log = True, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97f74f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271295, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "      <th>citation_words</th>\n",
       "      <th>distance</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Regarding, textual, context, ,, we, evaluated...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Within, Distributional, methods, ,, we, intro...</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>5.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_id  paper_id  sentence                                      text  \\\n",
       "0             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "1             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "2             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "3             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "4             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "\n",
       "                                     sentence_words  \\\n",
       "0  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "1  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "2  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "3  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "4  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "\n",
       "                                      citation_words  distance  \\\n",
       "0  [Regarding, textual, context, ,, we, evaluated...        21   \n",
       "1  [Evaluating, the, recent, dense, word, embeddi...        23   \n",
       "2  [Evaluating, the, recent, dense, word, embeddi...        23   \n",
       "3  [2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...        20   \n",
       "4  [Within, Distributional, methods, ,, we, intro...        38   \n",
       "\n",
       "   sentence_length       wer  \n",
       "0                7  3.000000  \n",
       "1                7  3.285714  \n",
       "2                7  3.285714  \n",
       "3                7  2.857143  \n",
       "4                7  5.428571  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation = sentence_citation.assign(\n",
    "    distance = distances, \n",
    "    sentence_length = lambda df: df.sentence_words.map(len)\n",
    ")\\\n",
    ".assign(wer = lambda df: df.distance / df.sentence_length)\\\n",
    "\n",
    "show(sentence_citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e07cc6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    271295.000000\n",
       "mean         12.414047\n",
       "std          15.709022\n",
       "min           0.000000\n",
       "25%           1.086957\n",
       "50%           2.761905\n",
       "75%          22.000000\n",
       "max          84.000000\n",
       "Name: wer, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation.wer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e8562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_citation.wer.plot.hist(bins = 200, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fc8f79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_citation.query(\"wer < 1\").wer.plot.hist(bins = 50, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c45b06f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation\\\n",
    ".query(\"wer < 0.6\")\\\n",
    ".sort_values(\"wer\", ascending = False)\\\n",
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe5620af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation\\\n",
    ".query(\"wer < 0.5\")\\\n",
    ".sort_values(\"wer\", ascending = False)\\\n",
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5c7e3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation\\\n",
    ".query(\"wer < 0.4\")\\\n",
    ".sort_values(\"wer\", ascending = False)\\\n",
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdbdc1cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation\\\n",
    ".query(\"wer < 0.2\")\\\n",
    ".sort_values(\"wer\", ascending = False)\\\n",
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec7e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271295, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "      <th>citation_words</th>\n",
       "      <th>distance</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>wer</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Regarding, textual, context, ,, we, evaluated...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Evaluating, the, recent, dense, word, embeddi...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>List of Abbreviations and Symbols Used .</td>\n",
       "      <td>[List, of, Abbreviations, and, Symbols, Used, .]</td>\n",
       "      <td>[Within, Distributional, methods, ,, we, intro...</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_id  paper_id  sentence                                      text  \\\n",
       "0             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "1             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "2             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "3             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "4             0        84         0  List of Abbreviations and Symbols Used .   \n",
       "\n",
       "                                     sentence_words  \\\n",
       "0  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "1  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "2  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "3  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "4  [List, of, Abbreviations, and, Symbols, Used, .]   \n",
       "\n",
       "                                      citation_words  distance  \\\n",
       "0  [Regarding, textual, context, ,, we, evaluated...        21   \n",
       "1  [Evaluating, the, recent, dense, word, embeddi...        23   \n",
       "2  [Evaluating, the, recent, dense, word, embeddi...        23   \n",
       "3  [2013, [, 134, ], ✗, ✓, (, Wikipedia, Text, ),...        20   \n",
       "4  [Within, Distributional, methods, ,, we, intro...        38   \n",
       "\n",
       "   sentence_length       wer  relevant  \n",
       "0                7  3.000000     False  \n",
       "1                7  3.285714     False  \n",
       "2                7  3.285714     False  \n",
       "3                7  2.857143     False  \n",
       "4                7  5.428571     False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_citation = sentence_citation.assign(relevant = lambda df: df.wer < 0.5)\n",
    "show(sentence_citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79cb0e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27140, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>1041-4347 (c) 2020 IEEE.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>Personal use is permitted, but republication/r...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>See http://www.ieee.org/publications_standards...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>Index Terms—Natural language processing, named...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>NER not only acts as a standalone tool for inf...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  sentence  reference_id  relevant  \\\n",
       "0        12         0            19     False   \n",
       "1        12         1            19     False   \n",
       "2        12         2            19     False   \n",
       "3        12         3            19     False   \n",
       "4        12         4            19     False   \n",
       "\n",
       "                                                text  sentence_words  \n",
       "0                           1041-4347 (c) 2020 IEEE.               7  \n",
       "1  Personal use is permitted, but republication/r...              11  \n",
       "2  See http://www.ieee.org/publications_standards...               8  \n",
       "3  Index Terms—Natural language processing, named...              45  \n",
       "4  NER not only acts as a standalone tool for inf...              82  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_labels = sentence_citation.groupby([\"paper_id\", \"sentence\", \"reference_id\"])\\\n",
    ".relevant.sum()\\\n",
    ".map(lambda x: x > 0)\\\n",
    ".reset_index()\\\n",
    ".merge(task_sentences)\\\n",
    ".assign(sentence_words = lambda df: df.sentence_words.map(len))\n",
    "\n",
    "show(task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9dd9c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_id  paper_id\n",
       "0             84          0.714286\n",
       "1             482         0.437500\n",
       "2             817         0.857143\n",
       "3             1031        0.500000\n",
       "4             302         0.750000\n",
       "5             405         0.400000\n",
       "6             1031        0.875000\n",
       "7             380         0.857143\n",
       "8             1031        0.700000\n",
       "9             722         0.833333\n",
       "10            979         1.000000\n",
       "11            926         0.714286\n",
       "12            213         0.666667\n",
       "13            38          0.600000\n",
       "14            715         0.666667\n",
       "15            217         0.857143\n",
       "16            578         0.600000\n",
       "17            14          0.800000\n",
       "18            482         0.800000\n",
       "19            12          0.571429\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_labels.query(\"relevant == True\").groupby([\"reference_id\", \"paper_id\"]).size() \\\n",
    "/ task_pool.set_index([\"reference_id\", \"paper_id\"]).mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484b1b1",
   "metadata": {},
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eac3f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 2\n",
    "paper = 817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7698f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Attention Is All You Need', 'Self-Attentive Hawkes Process')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references.title[ref], papers.title[paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03ff60f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These query vectors are used to find which part of the input sequence is more contributory (Vaswani et al., 2017).',\n",
       " 'Self-attention is a special case of the attention mechanism (Vaswani et al., 2017), where the query vectors Q, like (K,V ), are from the encoder side.',\n",
       " 'Self-attention is very expressive and flexible for both longterm and local dependencies, which used to be modeled by recurrent neural networks (RNNs) and convolutional neural networks (CNNs) (Vaswani et al., 2017).',\n",
       " 'Recently, a variety of Natural Language Processing (NLP) tasks have experienced large improvements thanks to self-attention (Vaswani et al., 2017; Devlin et al., 2018).',\n",
       " 'This allows the model to jointly attend information from different representation subspaces (Vaswani et al., 2017).',\n",
       " 'coding is replaced with the standard one as in (Vaswani et al., 2017).',\n",
       " 'However, RNN and its variants have been empirically proved to be less competent than self-attention in NLP (Vaswani et al., 2017; Devlin et al., 2018).']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations.query(\"reference_id == @ref and paper_id == @paper\")\\\n",
    ".context\\\n",
    ".str.replace(r\"\\s*\\[.+?\\]\", \"\", regex = True)\\\n",
    ".tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f018c280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These query vectors are used to find which part of the input sequence is more contributory (Vaswani et al., 2017).',\n",
       " 'Self-attention is a special case of the attention mechanism (Vaswani et al., 2017), where the query vectors Q, like (K,V ), are from the encoder side.',\n",
       " 'Self-attention is very expressive and flexible for both longterm and local dependencies, which used to be modeled by recurrent neural networks (RNNs) and convolutional neural networks (CNNs) (Vaswani et al., 2017).',\n",
       " 'Recently, a variety of Natural Language Processing (NLP) tasks have experienced large improvements thanks to self-attention (Vaswani et al., 2017; Devlin et al., 2018).',\n",
       " 'This allows the model to jointly attend information from different representation subspaces (Vaswani et al., 2017).',\n",
       " 'However, RNN and its variants have been empirically proved to be less competent than self-attention in NLP (Vaswani et al., 2017; Devlin et al., 2018).']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_labels\\\n",
    ".query(\"reference_id == @ref and paper_id == @paper and relevant == True\")\\\n",
    ".text\\\n",
    ".str.replace(r\"\\s*\\[.+?\\]\", \"\", regex = True)\\\n",
    ".tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dae659",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96ad183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>12</td>\n",
       "      <td>304</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>The use of neural models for NER was pioneered...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>12</td>\n",
       "      <td>344</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>[17] proposed a sentence approach network wher...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>12</td>\n",
       "      <td>479</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>Many deep learning based NER models use a CRF ...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>12</td>\n",
       "      <td>568</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>[17] trained a window/sentence approach networ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>These tasks include sentence-level tasks such ...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id  sentence  reference_id  relevant  \\\n",
       "304        12       304            19      True   \n",
       "344        12       344            19      True   \n",
       "479        12       479            19      True   \n",
       "568        12       568            19      True   \n",
       "768        14         3            17      True   \n",
       "\n",
       "                                                  text  sentence_words  \n",
       "304  The use of neural models for NER was pioneered...              29  \n",
       "344  [17] proposed a sentence approach network wher...              25  \n",
       "479  Many deep learning based NER models use a CRF ...              59  \n",
       "568  [17] trained a window/sentence approach networ...              21  \n",
       "768  These tasks include sentence-level tasks such ...              90  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sentences = task_labels.query(\"relevant == True\")\n",
    "show(positive_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e2f6366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>482</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>817</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1031</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>302</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>405</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1031</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>380</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1031</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>722</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>979</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>926</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>213</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>715</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>217</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>578</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>482</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reference_id  paper_id   0\n",
       "0              0        84  20\n",
       "1              1       482  23\n",
       "2              2       817  24\n",
       "3              3      1031  25\n",
       "4              4       302  27\n",
       "5              5       405  28\n",
       "6              6      1031  23\n",
       "7              7       380  24\n",
       "8              8      1031  23\n",
       "9              9       722  25\n",
       "10            10       979  23\n",
       "11            11       926  25\n",
       "12            12       213  28\n",
       "13            13        38  27\n",
       "14            14       715  26\n",
       "15            15       217  24\n",
       "16            16       578  27\n",
       "17            17        14  26\n",
       "18            18       482  26\n",
       "19            19        12  26"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = (30 - task_labels.query(\"relevant == True\").groupby([\"reference_id\", \"paper_id\"])\\\n",
    "               .size()).reset_index()\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27ab0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>84</td>\n",
       "      <td>6033</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>For the avoidance of doubt, Springer has the r...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>84</td>\n",
       "      <td>4409</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NGED, similar to edit distance of strings, tri...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>84</td>\n",
       "      <td>4880</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LambdaMart is a list-wise approach that aims t...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>84</td>\n",
       "      <td>3366</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4 2.1 Word2vec embedding: CBOW vs Skip-gram .</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>84</td>\n",
       "      <td>5121</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Section 3.6.1 7. rvsPagerank: cosine similarit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  sentence  reference_id  relevant  \\\n",
       "7362        84      6033             0     False   \n",
       "5738        84      4409             0     False   \n",
       "6209        84      4880             0     False   \n",
       "4695        84      3366             0     False   \n",
       "6450        84      5121             0     False   \n",
       "\n",
       "                                                   text  sentence_words  \n",
       "7362  For the avoidance of doubt, Springer has the r...              26  \n",
       "5738  NGED, similar to edit distance of strings, tri...              33  \n",
       "6209  LambdaMart is a list-wise approach that aims t...              14  \n",
       "4695      4 2.1 Word2vec embedding: CBOW vs Skip-gram .               9  \n",
       "6450  Section 3.6.1 7. rvsPagerank: cosine similarit...              13  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_samples = []\n",
    "for ref, paper, size in sample_size.values:\n",
    "    negative_samples.append(\n",
    "        task_labels\\\n",
    "        .query(f\"relevant == False and reference_id == {ref} and paper_id == {paper} and sentence_words > 5\")\\\n",
    "        .sample(n = size)\n",
    "    )\n",
    "negative_sentences = pd.concat(negative_samples)\n",
    "show(negative_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b7701d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>relevant</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>84</td>\n",
       "      <td>3366</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4 2.1 Word2vec embedding: CBOW vs Skip-gram .</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>84</td>\n",
       "      <td>3750</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>xv Chapter 1 Introduction “Concepts1 are the c...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>84</td>\n",
       "      <td>3819</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>We refer to this entity as the key entity.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>84</td>\n",
       "      <td>3832</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Regarding textual context, we evaluated multip...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>84</td>\n",
       "      <td>3878</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>This relation can be the well known taxonomic ...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  sentence  reference_id  relevant  \\\n",
       "4695        84      3366             0     False   \n",
       "5079        84      3750             0     False   \n",
       "5148        84      3819             0     False   \n",
       "5161        84      3832             0      True   \n",
       "5207        84      3878             0     False   \n",
       "\n",
       "                                                   text  sentence_words  \n",
       "4695      4 2.1 Word2vec embedding: CBOW vs Skip-gram .               9  \n",
       "5079  xv Chapter 1 Introduction “Concepts1 are the c...              16  \n",
       "5148         We refer to this entity as the key entity.              10  \n",
       "5161  Regarding textual context, we evaluated multip...              23  \n",
       "5207  This relation can be the well known taxonomic ...              42  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = pd.concat((positive_sentences, negative_sentences))\\\n",
    ".sort_values([\"reference_id\", \"paper_id\", \"sentence\"])\n",
    "\n",
    "show(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "276a6de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_id\n",
       "12      30\n",
       "14      30\n",
       "38      30\n",
       "84      30\n",
       "213     30\n",
       "217     30\n",
       "302     30\n",
       "380     30\n",
       "405     30\n",
       "482     60\n",
       "578     30\n",
       "715     30\n",
       "722     30\n",
       "817     30\n",
       "926     30\n",
       "979     30\n",
       "1031    90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.groupby(\"paper_id\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f984b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_id\n",
       "0     30\n",
       "1     30\n",
       "2     30\n",
       "3     30\n",
       "4     30\n",
       "5     30\n",
       "6     30\n",
       "7     30\n",
       "8     30\n",
       "9     30\n",
       "10    30\n",
       "11    30\n",
       "12    30\n",
       "13    30\n",
       "14    30\n",
       "15    30\n",
       "16    30\n",
       "17    30\n",
       "18    30\n",
       "19    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.groupby(\"reference_id\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "694dd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a1c0666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
       " 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references.title[ref], references.abstract[ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8504bb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,\n",
       "        'The computational costs of inference with transformers has led to alternatives and variants that aim for different tradeoffs, both within multi-stage architectures as well as with dense learned representations.'],\n",
       "       [True,\n",
       "        'This survey provides an overview of text ranking with a family of neural network models known as transformers, of which BERT (Bidirectional Encoder Representations from Transformers), an invention of Google, is the best-known example.'],\n",
       "       [False,\n",
       "        'We give this example because it is easy to convey, but the general idea of using heuristics to automatically gather training examples to train a classifier in NLP dates back to Yarowsky, in the context of word sense disambiguation.13 Data augmentation refers to techniques that exploit a set of training examples to gather or create additional training examples.'],\n",
       "       [True, 'BERT arrived on the scene in October 2018.'],\n",
       "       [False,\n",
       "        'If a relevant document does not appear in the top k, then that query receives a score of zero.'],\n",
       "       [False,\n",
       "        'Average Precision (AP) is defined as: AP(R, q) = ∑ (i,d)∈R Precision@i(R, q) · rel(q, d)∑ d∈C rel(q, d) , (6) where all notation used have already been defined.'],\n",
       "       [False,\n",
       "        'Initially, the dataset was designed to study question answering on web passages, but it was later adapted into traditional ad hoc ranking tasks.'],\n",
       "       [False,\n",
       "        'More generally, it is almost never reported in papers how many different techniques the researchers had tried before obtaining a positive result.'],\n",
       "       [False,\n",
       "        'In truth, there is “leakage” any time researchers evaluate on test data—at the very least, the researchers obtain a single bit of information: Is this technique effective or not?'],\n",
       "       [True,\n",
       "        ' had already shown BERT to be effective for text classification tasks, and the adaptation by Nogueira and Cho—known as monoBERT—has proven to be a simple, robust, effective, and widely replicated model for text ranking.'],\n",
       "       [True,\n",
       "        'At its core, BERT (Bidirectional Encoder Representations from Transformers) is a neural network model for generating contextual embeddings for input sequences in English, with a multilingual variant (often called “mBERT”) that can process input in over 100 different languages.'],\n",
       "       [False,\n",
       "        ', which was designed for sequence-to-sequence tasks (i.e., where both the input and output are sequences of tokens) such as machine translation.'],\n",
       "       [True,\n",
       "        ' hypothesized that NSP pretraining is important for downstream tasks, especially those that take two inputs.'],\n",
       "       [True,\n",
       "        'While the original paper presented only the BERTBase and BERTLarge configurations, with 12 and 24 transformer encoder layers, respectively, in later work Turc et al.'],\n",
       "       [False,\n",
       "        'While open source (sharing code) and open science (sharing data and models) have become the norms in recent years, as noted by Lin, the decision to share BERT wasn’t necessarily a given.'],\n",
       "       [False,\n",
       "        'The community is fortunate that things turned out the way they did, and Google should be given credit for its openness.'],\n",
       "       [False,\n",
       "        'Experimental results are presented in Figure 10, which shows that MRR@10 monotonically decreases as we increase the weight placed on BM25 scores.'],\n",
       "       [False, ', p cls n).'],\n",
       "       [False,\n",
       "        'Using the above length limits, for the MS MARCO passage ranking test collection, Nogueira et al.'],\n",
       "       [False,\n",
       "        'Thus, cascade transformers have the effect of reducing the average batch size, which increases throughput on GPUs compared to a monolithic design, where inference must be applied to all input instances.'],\n",
       "       [False,\n",
       "        'Perhaps the distinction lies in the “end-to-end” differentiability of the model (and hence how it is trained)?'],\n",
       "       [False,\n",
       "        ' extended TK with the Conformer Kernel (CK) model, which adds an explicit term-matching component based on BM25 and two efficiency improvements: assuming query term independence and replacing the transformer encoder layers with new “conformer” layers.'],\n",
       "       [False,\n",
       "        'Currently, we still lack definitive answers, but this represents an interesting future direction worth exploring.'],\n",
       "       [True,\n",
       "        'These gains are only 117In the original BERT paper, embeddings from this layer were more effective for named entity recognition than embeddings from the twelfth (last) layer (see Table 7).'],\n",
       "       [False,\n",
       "        'In contrast, the performance impact of DeepCT is negligible, as experimentally validated by Mackenzie et al.'],\n",
       "       [False,\n",
       "        ' also evaluated other less effective PGT variants that make changes to the feedback document representations (e.g., by not prepending the query and candidate document) or to the graph structure (e.g., by including a node for the query and candidate document).'],\n",
       "       [False,\n",
       "        'There is, unfortunately, no precise, widely agreed upon definition of what this means, except by illustration.'],\n",
       "       [False,\n",
       "        'In presenting the first class of methods to ranking with learned dense representations—dense retrieval with simple transformer bi-encoders—let us begin with a recap of the problem formulation presented in Section 5.1.'],\n",
       "       [False,\n",
       "        'demonstrated the effectiveness of multi-vector representational approaches, the effectiveness of ME-BERT appears to lag behind other dense retrieval techniques in absolute terms.'],\n",
       "       [False,\n",
       "        'The authors called this model TCT-ColBERT, where TCT stands for “Tightly Coupled Teacher”.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks\\\n",
    ".query(f\"reference_id == {ref}\")\\\n",
    ".assign(clean_text = lambda df: df.text.str.replace(r\"\\s*\\[.+?\\]\", \"\", regex = True))\\\n",
    "[[\"relevant\", \"clean_text\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e5e3fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors called this model TCT-ColBERT, where TCT stands for “Tightly Coupled Teacher”.\n",
      "\n",
      "While the original paper [Devlin et al., 2019] presented only the BERTBase and BERTLarge configurations, with 12 and 24 transformer encoder layers, respectively, in later work Turc et al.\n",
      "\n",
      "These gains are only 117In the original BERT paper [Devlin et al., 2019], embeddings from this layer were more effective for named entity recognition than embeddings from the twelfth (last) layer (see Table 7).\n",
      "\n",
      "More generally, it is almost never reported in papers how many different techniques the researchers had tried before obtaining a positive result.\n",
      "\n",
      "Currently, we still lack definitive answers, but this represents an interesting future direction worth exploring.\n",
      "\n",
      "demonstrated the effectiveness of multi-vector representational approaches, the effectiveness of ME-BERT appears to lag behind other dense retrieval techniques in absolute terms.\n",
      "\n",
      ", p cls n [i]).\n",
      "\n",
      "The computational costs of inference with transformers has led to alternatives and variants that aim for different tradeoffs, both within multi-stage architectures as well as with dense learned representations.\n",
      "\n",
      "If a relevant document does not appear in the top k, then that query receives a score of zero.\n",
      "\n",
      "There is, unfortunately, no precise, widely agreed upon definition of what this means, except by illustration.\n",
      "\n",
      "While open source (sharing code) and open science (sharing data and models) have become the norms in recent years, as noted by Lin [2019], the decision to share BERT wasn’t necessarily a given.\n",
      "\n",
      "[2019] hypothesized that NSP pretraining is important for downstream tasks, especially those that take two inputs.\n",
      "\n",
      "[2019] had already shown BERT to be effective for text classification tasks, and the adaptation by Nogueira and Cho—known as monoBERT—has proven to be a simple, robust, effective, and widely replicated model for text ranking.\n",
      "\n",
      "Using the above length limits, for the MS MARCO passage ranking test collection, Nogueira et al.\n",
      "\n",
      "Experimental results are presented in Figure 10, which shows that MRR@10 monotonically decreases as we increase the weight placed on BM25 scores.\n",
      "\n",
      "Average Precision (AP) is defined as: AP(R, q) = ∑ (i,d)∈R Precision@i(R, q) · rel(q, d)∑ d∈C rel(q, d) , (6) where all notation used have already been defined.\n",
      "\n",
      "This survey provides an overview of text ranking with a family of neural network models known as transformers, of which BERT (Bidirectional Encoder Representations from Transformers) [Devlin et al., 2019], an invention of Google, is the best-known example.\n",
      "\n",
      "The community is fortunate that things turned out the way they did, and Google should be given credit for its openness.\n",
      "\n",
      "Thus, cascade transformers have the effect of reducing the average batch size, which increases throughput on GPUs compared to a monolithic design, where inference must be applied to all input instances.\n",
      "\n",
      "[2021] also evaluated other less effective PGT variants that make changes to the feedback document representations (e.g., by not prepending the query and candidate document) or to the graph structure (e.g., by including a node for the query and candidate document).\n",
      "\n",
      "BERT [Devlin et al., 2019] arrived on the scene in October 2018.\n",
      "\n",
      "Perhaps the distinction lies in the “end-to-end” differentiability of the model (and hence how it is trained)?\n",
      "\n",
      "Initially, the dataset was designed to study question answering on web passages, but it was later adapted into traditional ad hoc ranking tasks.\n",
      "\n",
      "At its core, BERT (Bidirectional Encoder Representations from Transformers) [Devlin et al., 2019] is a neural network model for generating contextual embeddings for input sequences in English, with a multilingual variant (often called “mBERT”) that can process input in over 100 different languages.\n",
      "\n",
      "In truth, there is “leakage” any time researchers evaluate on test data—at the very least, the researchers obtain a single bit of information: Is this technique effective or not?\n",
      "\n",
      "In contrast, the performance impact of DeepCT is negligible, as experimentally validated by Mackenzie et al.\n",
      "\n",
      "[2020] extended TK with the Conformer Kernel (CK) model, which adds an explicit term-matching component based on BM25 and two efficiency improvements: assuming query term independence [Mitra et al., 2019] and replacing the transformer encoder layers with new “conformer” layers.\n",
      "\n",
      "[2017], which was designed for sequence-to-sequence tasks (i.e., where both the input and output are sequences of tokens) such as machine translation.\n",
      "\n",
      "In presenting the first class of methods to ranking with learned dense representations—dense retrieval with simple transformer bi-encoders—let us begin with a recap of the problem formulation presented in Section 5.1.\n",
      "\n",
      "We give this example because it is easy to convey, but the general idea of using heuristics to automatically gather training examples to train a classifier in NLP dates back to Yarowsky [1995], in the context of word sense disambiguation.13 Data augmentation refers to techniques that exploit a set of training examples to gather or create additional training examples.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tasks\\\n",
    "    .sample(frac = 1)\\\n",
    "    .groupby(\"reference_id\")\\\n",
    "    .text\\\n",
    "    .agg(lambda x: \"\\n\\n\".join(x))\\\n",
    "    [1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872da43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
