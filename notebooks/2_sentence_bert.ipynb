{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78cff1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import math\n",
    "from rouge import Rouge\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6dbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(x):\n",
    "    print(x.shape)\n",
    "    return x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0595f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28319, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_reference_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Distributed Representations of Words and Phras...</td>\n",
       "      <td>The recently introduced continuous Skip-gram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERT: Pre-training of Deep Bidirectional Trans...</td>\n",
       "      <td>We introduce a new language representation m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GloVe : Global Vectors for Word Representation</td>\n",
       "      <td>Recent methods for learning vector space repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attention Is All You Need</td>\n",
       "      <td>The dominant sequence transduction models ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam: A Method for Stochastic Optimization</td>\n",
       "      <td>We introduce Adam, an algorithm for first-or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long Short-Term Memory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep Contextualized Word Representations</td>\n",
       "      <td>We introduce a new type of deep contextualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Efficient Estimation of Word Representations i...</td>\n",
       "      <td>We propose two novel model architectures for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Machine Translation By Jointly Learning...</td>\n",
       "      <td>Neural machine translation is a recently pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>Deeper neural networks are more difficult to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 title  \\\n",
       "global_reference_id                                                      \n",
       "0                    Distributed Representations of Words and Phras...   \n",
       "1                    BERT: Pre-training of Deep Bidirectional Trans...   \n",
       "2                       GloVe : Global Vectors for Word Representation   \n",
       "3                                            Attention Is All You Need   \n",
       "4                           Adam: A Method for Stochastic Optimization   \n",
       "5                                               Long Short-Term Memory   \n",
       "6                             Deep Contextualized Word Representations   \n",
       "7                    Efficient Estimation of Word Representations i...   \n",
       "8                    Neural Machine Translation By Jointly Learning...   \n",
       "9                         Deep Residual Learning for Image Recognition   \n",
       "\n",
       "                                                              abstract  \n",
       "global_reference_id                                                     \n",
       "0                      The recently introduced continuous Skip-gram...  \n",
       "1                      We introduce a new language representation m...  \n",
       "2                    Recent methods for learning vector space repre...  \n",
       "3                      The dominant sequence transduction models ar...  \n",
       "4                      We introduce Adam, an algorithm for first-or...  \n",
       "5                                                                  NaN  \n",
       "6                      We introduce a new type of deep contextualiz...  \n",
       "7                      We propose two novel model architectures for...  \n",
       "8                      Neural machine translation is a recently pro...  \n",
       "9                      Deeper neural networks are more difficult to...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = pd.read_csv(\"../data/references.csv\").set_index(\"global_reference_id\")\n",
    "show(references)\n",
    "references.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3eb55bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDST at TREC 2019 Deep Learning Track: Deep Ca...</td>\n",
       "      <td>This paper describes our participation in the ...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BatchBALD: Efficient and Diverse Batch Acquisi...</td>\n",
       "      <td>We develop BatchBALD, a tractable approximatio...</td>\n",
       "      <td>A key problem in deep learning is data efficie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Sentence Compression Based Framework to Quer...</td>\n",
       "      <td>We consider the problem of using sentence comp...</td>\n",
       "      <td>Proceedings of the 51st Annual Meeting of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DR-BiLSTM: Dependent Reading Bidirectional LST...</td>\n",
       "      <td>We present a novel deep learning architecture ...</td>\n",
       "      <td>Natural Language Inference (NLI; a.k.a. Recogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mental health consequences of infections by co...</td>\n",
       "      <td>1The Department of Cerebrovascular Diseases, T...</td>\n",
       "      <td>Brain and Behavior. 2020;00:e01901. | 1 of 7 h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "paper_id                                                      \n",
       "2         IDST at TREC 2019 Deep Learning Track: Deep Ca...   \n",
       "3         BatchBALD: Efficient and Diverse Batch Acquisi...   \n",
       "4         A Sentence Compression Based Framework to Quer...   \n",
       "5         DR-BiLSTM: Dependent Reading Bidirectional LST...   \n",
       "6         Mental health consequences of infections by co...   \n",
       "\n",
       "                                                   abstract  \\\n",
       "paper_id                                                      \n",
       "2         This paper describes our participation in the ...   \n",
       "3         We develop BatchBALD, a tractable approximatio...   \n",
       "4         We consider the problem of using sentence comp...   \n",
       "5         We present a novel deep learning architecture ...   \n",
       "6         1The Department of Cerebrovascular Diseases, T...   \n",
       "\n",
       "                                                       text  \n",
       "paper_id                                                     \n",
       "2         KEYWORDS cascade ranking, pre-trained language...  \n",
       "3         A key problem in deep learning is data efficie...  \n",
       "4         Proceedings of the 51st Annual Meeting of the ...  \n",
       "5         Natural Language Inference (NLI; a.k.a. Recogn...  \n",
       "6         Brain and Behavior. 2020;00:e01901. | 1 of 7 h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv(\"../data/papers.csv\").set_index(\"paper_id\")\n",
    "show(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb10135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62988, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>internal_reference_id</th>\n",
       "      <th>global_reference_id</th>\n",
       "      <th>context</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8672</td>\n",
       "      <td>JOURNAL OF COMBINATORIAL THEORY 9, 129--135 (1...</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Our approach is mainly based on the BERT langu...</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>521</td>\n",
       "      <td>Different from many other ranking methods whic...</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>Moreover, for full ranking subtask, we use a s...</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>The proposed model is based on the pointer-gen...</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  internal_reference_id  global_reference_id  \\\n",
       "0         1                      0                 8672   \n",
       "1         2                      1                    1   \n",
       "2         2                      8                  521   \n",
       "3         2                      5                  171   \n",
       "4         2                      6                   27   \n",
       "\n",
       "                                             context  start_offset  end_offset  \n",
       "0  JOURNAL OF COMBINATORIAL THEORY 9, 129--135 (1...            36          51  \n",
       "1  Our approach is mainly based on the BERT langu...            56          59  \n",
       "2  Different from many other ranking methods whic...           216         219  \n",
       "3  Moreover, for full ranking subtask, we use a s...            78          81  \n",
       "4  The proposed model is based on the pointer-gen...            59          62  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations = pd.read_csv(\"../data/citations.csv\")\n",
    "show(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2a6615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_id  global_reference_id\n",
       "1         8672                   1\n",
       "2         1                      2\n",
       "          3                      1\n",
       "          12                     1\n",
       "          20                     1\n",
       "                                ..\n",
       "1364      21077                  1\n",
       "          21363                  1\n",
       "          21979                  1\n",
       "          24086                  1\n",
       "          25998                  1\n",
       "Length: 36096, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations.groupby([\"paper_id\", \"global_reference_id\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19513d8",
   "metadata": {},
   "source": [
    "# retrieving sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bcf54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21673, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>global_reference_id</th>\n",
       "      <th>reference_abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>We introduce a new language representation m...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>We introduce a new language representation m...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>521</td>\n",
       "      <td>Recently, the pre-trained language model, BE...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>521</td>\n",
       "      <td>Recently, the pre-trained language model, BE...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>521</td>\n",
       "      <td>Recently, the pre-trained language model, BE...</td>\n",
       "      <td>KEYWORDS cascade ranking, pre-trained language...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  global_reference_id  \\\n",
       "0         2                    1   \n",
       "1         2                    1   \n",
       "2         2                  521   \n",
       "3         2                  521   \n",
       "4         2                  521   \n",
       "\n",
       "                                  reference_abstract  \\\n",
       "0    We introduce a new language representation m...   \n",
       "1    We introduce a new language representation m...   \n",
       "2    Recently, the pre-trained language model, BE...   \n",
       "3    Recently, the pre-trained language model, BE...   \n",
       "4    Recently, the pre-trained language model, BE...   \n",
       "\n",
       "                                          paper_text  \n",
       "0  KEYWORDS cascade ranking, pre-trained language...  \n",
       "1  KEYWORDS cascade ranking, pre-trained language...  \n",
       "2  KEYWORDS cascade ranking, pre-trained language...  \n",
       "3  KEYWORDS cascade ranking, pre-trained language...  \n",
       "4  KEYWORDS cascade ranking, pre-trained language...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = citations[[\"paper_id\", \"global_reference_id\"]]\\\n",
    ".merge(references.drop(columns = \"title\"), on = \"global_reference_id\")\\\n",
    ".merge(papers.drop(columns = [\"abstract\", \"title\"]), on = \"paper_id\")\\\n",
    ".rename(columns = {\"abstract\":\"reference_abstract\", \"context\":\"hypothesis\", \"text\":\"paper_text\"})\\\n",
    ".dropna()\\\n",
    ".reset_index(drop = True)\n",
    "show(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a81614f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.tokenize.punkt.PunktSentenceTokenizer at 0x7f9c54a5b220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PunktSentenceTokenizer(train_text = papers.text.sum())\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a041bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "377cda6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be632f16ddc4323b93520cd2d649a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3298/2530885880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/malnis/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;31m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mall_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = queries.paper_text#.head()\n",
    "sentences = []\n",
    "for d in tqdm(data):\n",
    "    s = tokenizer.tokenize(d)\n",
    "    e = model.encode(s)\n",
    "    sentences.append(dict(sentences = np.array(s), embeddings = e))\n",
    "example = sentences[0]\n",
    "print(example[\"sentences\"].shape, example[\"embeddings\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c73d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4328, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_reference_id</th>\n",
       "      <th>reference_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We introduce a new language representation m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521</td>\n",
       "      <td>Recently, the pre-trained language model, BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>Neural sequence-to-sequence models have prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006</td>\n",
       "      <td>Sequence-to-Sequence (seq2seq) modeling has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>The dominant sequence transduction models ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_reference_id                                 reference_abstract\n",
       "0                    1    We introduce a new language representation m...\n",
       "2                  521    Recently, the pre-trained language model, BE...\n",
       "5                   27    Neural sequence-to-sequence models have prov...\n",
       "8                 2006    Sequence-to-Sequence (seq2seq) modeling has ...\n",
       "9                    3    The dominant sequence transduction models ar..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = queries[[\"global_reference_id\", \"reference_abstract\"]].drop_duplicates()\n",
    "show(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2241c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702e97b8b56a42c891d76b344fcb0c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4328, 384)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_embeddings = model.encode(q.reference_abstract.tolist(), show_progress_bar = True)\n",
    "# print(query_embeddings.shape)\n",
    "\n",
    "# with open(\"../emb/reference_abstracts.npy\", \"wb\") as file:\n",
    "#     pickle.dump(query_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14909cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4328, 384)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../emb/reference_abstracts.npy\", \"rb\") as file:\n",
    "    query_embeddings = pickle.load(file)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbac6a4",
   "metadata": {},
   "source": [
    "# rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hyps = queries.hypothesis, refs = queries.reference)\n",
    "print(len(scores))\n",
    "scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ce2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_df = pd.DataFrame.from_records(scores)\n",
    "show(rouge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ba082",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_1 = pd.DataFrame.from_records(rouge_df[\"rouge-1\"])\\\n",
    ".rename(columns = {\"f\":\"rouge_1_f\", \"r\":\"rouge_1_r\", \"p\":\"rouge_1_p\"})\n",
    "show(rouge_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bf379",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_2 = pd.DataFrame.from_records(rouge_df[\"rouge-2\"])\\\n",
    ".rename(columns = {\"f\":\"rouge_2_f\", \"r\":\"rouge_2_r\", \"p\":\"rouge_2_p\"})\n",
    "show(rouge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_l = pd.DataFrame.from_records(rouge_df[\"rouge-l\"])\\\n",
    ".rename(columns = {\"f\":\"rouge_l_f\", \"r\":\"rouge_l_r\", \"p\":\"rouge_l_p\"})\n",
    "show(rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13102fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rouge = pd.concat((queries, rouge_1, rouge_2, rouge_l), axis = 1)\n",
    "show(full_rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 1, sharex = True, constrained_layout=True, figsize = (12, 6))\n",
    "ax[0].hist(full_rouge.rouge_1_f, bins = 50)\n",
    "ax[0].set_title(\"Rouge-1\")\n",
    "ax[1].hist(full_rouge.rouge_2_f, bins = 50, color = \"green\")\n",
    "ax[1].set_title(\"Rouge-2\")\n",
    "ax[2].hist(full_rouge.rouge_l_f, bins = 50, color = \"red\")\n",
    "ax[2].set_title(\"Rouge-L\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75292c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_rouge.sort_values(\"rouge_1_f\").reset_index()\n",
    "f, ax = plt.subplots(3, 1, sharex = True, constrained_layout=True, figsize = (12, 6))\n",
    "ax[0].plot(data.rouge_1_f)\n",
    "ax[0].set_title(\"Rouge-1\")\n",
    "ax[1].plot(data.rouge_2_f, color = \"green\")\n",
    "ax[1].set_title(\"Rouge-2\")\n",
    "ax[2].plot(data.rouge_l_f, color = \"red\")\n",
    "ax[2].set_title(\"Rouge-L\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_rouge, vars = [\"rouge_1_f\",\"rouge_2_f\", \"rouge_l_f\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b576ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_rouge.sort_values(\"rouge_1_f\").reset_index()\n",
    "f, ax = plt.subplots(3, 1, sharex = True, constrained_layout=True, figsize = (12, 6))\n",
    "ax[0].plot(data.rouge_1_f)\n",
    "ax[0].set_title(\"Rouge-1 F\")\n",
    "ax[1].plot(data.rouge_1_p)\n",
    "ax[1].set_title(\"Rouge-1 P\")\n",
    "ax[2].plot(data.rouge_1_r)\n",
    "ax[2].set_title(\"Rouge-1 R\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2458293",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_rouge, vars = [\"rouge_1_f\",\"rouge_1_p\", \"rouge_1_r\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
